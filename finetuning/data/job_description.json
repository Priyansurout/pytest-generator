{
  "task_description": "Generate pytest unit test cases from function signatures and docstrings. The input is a function interface that includes a function signature with type hints, a docstring containing Args, Returns, and Raises sections, and an optional dependency declaration in the form '# Dependencies: func1(), func2()' if external dependencies exist. The output should be pytest test code that includes the required imports (pytest and unittest.mock), parametrized tests with 2-3 cases demonstrating usage patterns, mocking of all external dependencies, edge case testing, assertions for both return values and mock call verification, and error tests for each specified exception type. The test code must contain a maximum of three test functions per example and follow proper formatting with four-space indentation and no markdown or headers.",
  "input_description": "A Python function interface containing: (1) function signature with type hints, (2) comprehensive docstring with Args, Returns, and Raises sections, (3) optional dependency comment listing external functions to mock. The function may have zero or more parameters, may return values or None, and may raise specific exceptions. Dependencies are indicated via '# Dependencies: func1(), func2()' comment.",
  "llm_as_a_judge_instructions": "Compare the predicted pytest test code to the reference test code. Output 'good' if the predicted tests: (1) correctly mock all specified dependencies using unittest.mock, (2) include parametrized tests with appropriate test cases, (3) test edge cases and error conditions, (4) verify both return values and mock calls, (5) follow pytest conventions and proper Python formatting with four-space indentation. Minor variations in test data values or assertion styles are acceptable as long as the test coverage and patterns match. Output 'bad' if dependencies are not mocked, critical test cases are missing, or the code has syntax errors."
}